{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ITNPBD2 OpenCV in Python\n",
    "## Image manipulation and object detection\n",
    "\n",
    "# pip install opencv-python\n",
    "We also need matplotlib to display the images in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images are stored in NumPy arrays\n",
    "\n",
    "## Let's make one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = [[[x,x,x] for x in range(256)] for i in range(256)]\n",
    "img=np.array(img).astype(np.uint8)\n",
    "img[:,:,0]=255-img[:,:,0]\n",
    "img[:,:,1]=0\n",
    "\n",
    "#cv2.imshow('image',img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.title('Image')\n",
    "plt.show()\n",
    "\n",
    "#print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/mountain.jpg')\n",
    "plt.imshow(img)\n",
    "plt.title('Bannf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The colours don't look right!\n",
    "matplotlib expects RGB but opencv uses BGR as default, so we translate:\n",
    "I'll remove the axis lines and scale too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.title('Bannf')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is stored in the variable `img`?\n",
    "## It is a NumPy array of integers: h x w x 3 colour channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(type(img))\n",
    "print(img.shape)\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets take a closer look at the NumPy array\n",
    "- The shape is (rows, columns, 3)\n",
    "- Access a single pixel at `img[y,x]` - note the order row, column\n",
    "- Origin (0,0) is at top left of image\n",
    "- This gives the three colour channels. By default, RGB (if viewing with matplotlib)\n",
    "- So red intensity of pixel in row 5, column 10 is at `img[5,10,0]`, green is at `img[5,10,1]` and blue is at `img[5,10,2]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fade = [[[x,x,x] for x in range(256)] for i in range(256)]\n",
    "fade=np.array(fade).astype(np.uint8)\n",
    "fade[:,:,0]=255-fade[:,:,0]\n",
    "fade[:,:,1]=0\n",
    "\n",
    "'''\n",
    "# This shows the image in a new window and uses BGR colour scheme!!!\n",
    "cv2.imshow(\"test\", fade)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "'''\n",
    "\n",
    "plt.imshow(fade)\n",
    "plt.title('Fade')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Red intensity at 0,0 =\", fade[0,0,0])\n",
    "print(\"Red intensity at 0,255 =\", fade[0,255,0])\n",
    "print(\"Blue intensity at 0,0 =\", fade[0,0,2])\n",
    "print(\"Blue intensity at 0,255 =\", fade[0,255,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and Rotating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height,width,_ = img.shape\n",
    "bigger = cv2.resize(img,(2*width, 2*height), interpolation = cv2.INTER_CUBIC)\n",
    "print(bigger.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_matrix = cv2.getRotationMatrix2D((width / 2, height / 2), 90, 1)  # or -1 for other way\n",
    "rotated_image = cv2.warpAffine(img, rotation_matrix, (width, height))\n",
    "plt.imshow(rotated_image)\n",
    "plt.title('Bannf')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.circle(img,(100,100),50,(250,20,20),5)   # Make negative thickness to fill\n",
    "plt.imshow(img)\n",
    "plt.title('Bannf')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Edges and Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/parrot.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.title('Parrot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny edge detection\n",
    "threshold1 = 100\n",
    "threshold2 = 200\n",
    "canny = cv2.Canny(img, threshold1, threshold2)\n",
    "\n",
    "plt.imshow(canny, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blurring and other filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur=cv2.blur(img,(5,5))\n",
    "plt.imshow(blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny = cv2.Canny(blur, threshold1, threshold2)\n",
    "\n",
    "plt.imshow(canny, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = cv2.medianBlur(img,15)\n",
    "plt.imshow(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny = cv2.Canny(median, threshold1, threshold2)\n",
    "\n",
    "plt.imshow(canny, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Lines in an Image\n",
    "- Hough Transform finds lines and returns an array of polar coordinates\n",
    "- They are rho - distance from origin and theta - angle of perpendiular line to origin\n",
    "- Doesn't give the length of the line\n",
    "- Need to translate them into x,y coordinates for plotting on image\n",
    "\n",
    "<img src=\"Images/houghlines1.svg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/window.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/window.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.blur(gray,(2,2))\n",
    "edges = cv2.Canny(blur,50,150,apertureSize = 3)\n",
    "lines = cv2.HoughLines(edges,1,0.001,170)\n",
    "maxdim = max(img.shape)\n",
    "\n",
    "print(\"Found\",len(lines),\"lines\")\n",
    "\n",
    "def polar_to_cart(rho,theta, length):\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = int(x0 + length*(-b))\n",
    "    y1 = int(y0 + length*(a))\n",
    "    x2 = int(x0 - length*(-b))\n",
    "    y2 = int(y0 - length*(a))\n",
    "    return x1, x2, y1, y2\n",
    "\n",
    "for line in lines:\n",
    "    for rho,theta in line:\n",
    "        #print(\"Line: rho=\",rho,\"theta=\",theta)\n",
    "        x1, x2, y1, y2 = polar_to_cart(rho,theta, maxdim)\n",
    "        cv2.line(img,(x1,y1),(x2,y2),(0,0,255),3)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering by Colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/apple.jpg')\n",
    "rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(rgb)\n",
    "plt.title('Apple')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate the image into Hue Saturation, Value (HSV) space for colour processing\n",
    "## Good way to understand HSV space, use a colour chooser like the one in MS Paint ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "plt.imshow(hsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask out the regions that are red in HSV space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In HSV colour space, red occupies two main regions:\n",
    "\n",
    "# lower mask (0-10)\n",
    "lower_red = np.array([0,90,70])\n",
    "upper_red = np.array([10,255,255])\n",
    "mask0 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "# upper mask (170-180)\n",
    "lower_red = np.array([170,120,70])\n",
    "upper_red = np.array([180,255,255])\n",
    "mask1 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "# join my masks\n",
    "mask = mask0+mask1\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((6,6),np.uint8),iterations=2) # Remove dots\n",
    "\n",
    "# Convert colour space to grayscale\n",
    "#cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\n",
    "#cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.imshow(mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the image moments\n",
    "* Image moments are statistics calculated from the image intensity values\n",
    "* We will use them to calculate a centre of mass for the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = cv2.moments(mask, 0)\n",
    "\n",
    "cx = int(m['m10']/m['m00'])\n",
    "cy = int(m['m01']/m['m00'])\n",
    "\n",
    "print(cx,cy)\n",
    "\n",
    "img_marked = rgb.copy()\n",
    "cv2.circle(img_marked,(cx,cy),60,(250,20,20),-1)\n",
    "plt.imshow(img_marked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Calculate the image contours\n",
    "## Edge detection produces a new image where edges are a different colour\n",
    "## Contour calculation produces a list of points that make up a contour- an edge at the same height\n",
    "## There will be many in an image, so an array of countour sets is produced when calling `cv2.findContours`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours,_ = cv2.findContours(mask, 1, 2)\n",
    "print(len(contours))\n",
    "#cv2.drawContours(img, contours, -1, (0, 255, 0), 15)\n",
    "#plt.imshow(img)\n",
    "\n",
    "# minEnclosingCircle finds the smallest circle that encloses a contour\n",
    "# Here we find the largest and hope that is our apple\n",
    "maxr=0\n",
    "for cnt in contours:\n",
    "    (x,y),radius = cv2.minEnclosingCircle(cnt)\n",
    "    centre = (int(x),int(y))\n",
    "    radius = int(radius)\n",
    "    if(radius>maxr):\n",
    "        maxr = radius\n",
    "        maxc = centre\n",
    "if maxr > 0:\n",
    "    cv2.circle(img_marked,maxc,maxr,(255,0,0),20)\n",
    "\n",
    "\n",
    "plt.imshow(img_marked)\n",
    "print(x,y,radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply a mask to select only the pixels in the circle of the apple\n",
    "* Make a new image the same size as the first one\n",
    "* Create a mask for the circle around the apple\n",
    "* Use the mask to create two new images: apple, background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height,width,_ = img.shape\n",
    "applemask = np.zeros((height,width), np.uint8)\n",
    "cv2.circle(applemask,maxc,maxr,(255,255,255),-1)\n",
    "bgmask = cv2.bitwise_not(applemask)\n",
    "plt.imshow(bgmask,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask and add\n",
    "bg = cv2.bitwise_and(rgb,rgb,mask=bgmask)\n",
    "apple = cv2.bitwise_and(rgb,rgb,mask=applemask)\n",
    "plt.imshow(apple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, blur the background and add the images together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgblur = cv2.blur(img,(60, 60))\n",
    "bgblur = cv2.bitwise_and(bgblur, bgblur, mask=bgmask)\n",
    "final=bgblur+apple\n",
    "plt.imshow(final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Faces\n",
    "## Using Haar Cascades\n",
    "## Open CV comes with a set of detectors for facial features\n",
    "## They are defined in XML files, usually here:\n",
    "`...\\Lib\\site-packages\\cv2\\data`\n",
    "## Detectors for:\n",
    "* Eyes\n",
    "* Faces\n",
    "* Smiles\n",
    "* Upper / Lower body\n",
    "\n",
    "## Read about them here:\n",
    "<a href='https://docs.opencv.org/4.1.0/d7/d8b/tutorial_py_face_detection.html'>https://docs.opencv.org/4.1.0/d7/d8b/tutorial_py_face_detection.html</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Images/prize.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "classifier = cv2.CascadeClassifier(\"haar/haarcascade_frontalface_default.xml\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = classifier.detectMultiScale(gray, 1.1, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    \n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
